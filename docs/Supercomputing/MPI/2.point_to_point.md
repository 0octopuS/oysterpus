# 2. Point-to-point communication

!!! abstract "Take Away"
    - `MPI_Barrier`: Synchronization between processes wait until everybody within the communicator reaches the call.
    - `MPI_Send(void* data, int count, MPI_Datatype datatype, int destination, int tag, MPI_Comm communicator)`: send `count` data of type `datatype`. The `destination` is the rank of receiver, and `tag` belongs to the message.
    - `MPI_Recv(void* data, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm communicator, MPI_Status* status)`: arguments are similar to `MPI_Send`, with an additional `status` specifying the status of whether the message is received successfully.
    - `MPI_Get_count( const MPI_Status *status, MPI_Datatype datatype, int *count )`: number of received elements.

## 2.1 Message exchange

=== ":octicons-terminal-16: Code"
    ```c
    if (myid == 0) {
        MPI_Send(message, size, MPI_INT, 1,1,MPI_COMM_WORLD);
        MPI_Recv(receiveBuffer, size, MPI_INT, 1,2,MPI_COMM_WORLD, &status);
        int nrecv;
        MPI_Get_count(&status, MPI_INT, &nrecv);
        printf("Rank %i received %i elements, first %i\n", myid, nrecv, receiveBuffer[0]);
    } else if (myid == 1) {
        MPI_Send(message, size, MPI_INT, 0,2,MPI_COMM_WORLD);
        MPI_Recv(receiveBuffer, size, MPI_INT, 0,1,MPI_COMM_WORLD, &status);
        int nrecv;
        MPI_Get_count(&status, MPI_INT, &nrecv);
        printf("Rank %i received %i elements, first %i\n", myid, nrecv, receiveBuffer[0]);
    }
    ```
=== ":octicons-code-review-16: Puhti Result"
    ```sh
    Rank 0 received 100 elements, first 1
    Rank 1 received 100 elements, first 0
    ```

!!! question "Try increasing the message size (e.g. to 100000), recompile and run. What happens?"
    Get the result of time limit
    ```sh
    slurmstepd: error: *** STEP 20173362.0 ON r07c20 CANCELLED AT 2024-01-22T12:46:27 DUE TO TIME LIMIT ***
    ```
!!! question "What if you reorder the send and receive calls in one of the processes?"
    The program still run and get the correct answer.
    ```sh
    Rank 0 received 100 elements, first 1
    Rank 1 received 100 elements, first 0
    ```

## 2.2 Parallel pi with two processes Program

=== ":octicons-terminal-16: Code"

    ```cpp
    MPI_Init(&argc, &argv);
    MPI_Status status;
    int myid, istart, istop;
    MPI_Comm_rank(MPI_COMM_WORLD, &myid);
    printf("Computing approximation to pi with N=%d\n", n);
    // test id to decide range
    istart = myid == 0 ? 1: n/2+1;
    istop = myid == 0? n/2: n;
    // calculate result
    double pi = 0.0;
    for (int i=istart; i <= istop; i++) {
        double x = (i - 0.5) / n;
        pi += 1.0 / (1.0 + x*x);
    }
    pi *= 4.0 / n;
    // send or recv result based on id
    if(myid == 1){
        MPI_Send( &pi, 1, MPI_DOUBLE, 0 , 1, MPI_COMM_WORLD);
    } else{
        double pi_other;
        MPI_Recv( &pi_other , 1, MPI_DOUBLE ,1 , 1 , MPI_COMM_WORLD , &status);
        pi += pi_other;
        printf("Approximate pi=%18.16f (exact pi=%10.8f)\n", pi, M_PI);
    }    
    ```
=== ":octicons-code-review-16: Puhti Result(840)"
    ```tex
    Computing approximation to pi with N=840
    Approximate pi=3.1415927716925891
    Computing approximation to pi with N=840
    ```

!!! question "Compare the result to the that of the serial calculation, do you get exactly the same result? If not, can you explain why?"
    - Serial result  :pi=3.1415927716925873
    - Parallel result:pi=3.1415927716925891
    - Not the same possibly because of **division** operations in floating number losing accuracy. (`double x = (i - 0.5) / n, pi *= 4.0 / n`)
